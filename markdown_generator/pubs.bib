@journal{sattler2023hrps,
    author = {Sattler, Patrick and Zirngibl, Johannes and Jonker, Mattijs and Gasser, Oliver and Carle, Georg and   Holz, Ralph},
    title = {{Packed to the Brim: Investigating the Impact of Highly Responsive Prefixes on Internet-Wide           Measurement Campaigns}},
    year = {2023},
    file = {sattler2023hrps.pdf},
    url = {https://doi.org/10.1145/3629146},
    doi = {10.1145/3629146},
    abstract = {Internet-wide scans are an important tool to evaluate the deployment of services. To enable large-  scale application layer scans, a fast, stateless port scan (e.g., using ZMap) is often performed ahead of time to   collect responsive targets. It is a common expectation that port scans on the entire IPv4 address space provide a   relatively unbiased view as they cover the complete address space. Previous work, however, has found prefixes where all addresses share particular properties. In IPv6, aliased prefixes and fully responsive prefixes, i.e., prefixes  where all addresses are responsive, are a well-known phenomenon. However, there is no such in-depth analysis for    prefixes with these responsiveness patterns in IPv4.This paper delves into the underlying factors of this           phenomenon in the context of IPv4 and evaluates port scans on a total of 161 ports (142 TCP \& 19 UDP ports) from   three different vantage points. To account for packet loss and other scanning artifacts, we propose the notion of a new category of prefixes, which we call highly responsive prefixes (HRPs). Our findings show that the share of HRPs can make up 70\% of responsive addresses on selected ports. Regarding specific ports, we observe that CDNs          contribute to the largest fraction of HRPs on TCP/80 and TCP/443, while TCP proxies emerge as the primary cause of  HRPs on other ports. Our analysis also reveals that application layer handshakes to targets outside HRPs are,       depending on the chosen service, up to three times more likely to be successful compared to handshakes with targets located in HRPs. To improve future scanning campaigns conducted by the research community, we make our study's data publicly available and provide a tool for detecting HRPs. Furthermore, we propose an approach for a more efficient, ethical, and sustainable application layer target selection. We demonstrate that our approach has the potential to  reduce the number of TLS handshakes by up to 75\% during an Internet-wide scan while successfully obtaining 99 \%   of all unique certificates.},
    journal = {Proc. ACM Netw.},
    month = {nov},
    day = {28},
    homepage = {https://hrp-stats.github.io/},
}

@journal{sosnowski2024efactls,
  author = {Sosnowski, Markus and Zirngibl, Johannes and Sattler, Patrick and Carle, Georg and Grohnfeldt, Claas and Russo, Michele and Sgandurra, Daniele},
  journal = {{IEEE Transactions on Network and Service Management}},
  title = {{EFACTLS: Effective Active TLS Fingerprinting for Large-scale Server Deployment Characterization}},
  abstract = {Active measurements allow the collection of server characteristics on a large scale that can aid in discovering hidden relations and commonalities among server deployments. Finding these relations opens up new possibilities for clustering and classifying server deployments; for example, identifying a previously unknown cybercriminal infrastructure can be valuable cyber-threat intelligence. In this work, we propose a methodology based on  active measurements to acquire Transport Layer Security (TLS) metadata from servers and leverage it for fingerprinting. Our fingerprints capture characteristic behavior of the TLS stack, primarily influenced by the serverâ€™s         implementation, configuration, and hardware support. Using an empirical optimization strategy that maximizes information gained from every handshake to minimize measurement costs, we generated 10 general-purpose Client Hellos. They served as scanning probes to create an extensive database of TLS configurations to classify servers. We propose the Shannon Entropy to measure collected information and compare different approaches. This study fingerprinted 8       million servers from the Tranco top list and two Command and Control (C2) blocklists over 60 weeks with weekly snapshots. The resulting data formed the foundation for two long-term case studies: classification of Content Delivery   Network and C2 servers. Moreover, the detection was fine-grained enough to detect C2 server families. The proposed methodology demonstrated a precision of 99% and enabled a stable identification of new servers over time. This study shows how active measurements can provide valuable security-relevant insights and improve our understanding of the Internet.},
  year={2024},
  month = feb,
  doi={10.1109/TNSM.2024.3364526},
  Homepage = {https://tumi8.github.io/active-tls-fingerprinting/},
  rawdata = {https://doi.org/10.14459/2024mp1733820},
}

@journal{kempf2024quicperf,
  author = {Kempf, Marcel and Jaeger, Benedikt and Zirngibl, Johannes and Ploch, Kevin and Carle, Georg},
  title = {{QUIC on the Fast Lane: Extending Performance Evaluations on High-rate Links}},
  journal = {{Computer Communications}},
  year = {2024},
  doi = {10.1016/j.comcom.2024.04.038},
  url = {https://doi.org/10.1016/j.comcom.2024.04.038},
  abstract = {QUIC is a new protocol standardized in 2021 designed to improve on the widely used TCP/TLS stack. The main goal is to speed up web traffic via HTTP, but it is also used in other areas like tunneling. Based on UDP, it offers features like reliable in-order delivery, flow and congestion control, stream-based multiplexing, and always-on encryption using TLS 1.3. Unlike TCP, QUIC integrates these capabilities in user space, relying on kernel interaction solely for UDP. Operating in 
      user space allows more flexibility but sacrifices some kernel-level efficiency and optimization that TCP benefits from. Various QUIC implementations exist, each distinct in programming language, architecture, and design. QUIC is already widely deployed on the Internet and has been evaluated, focussing on low latency, interoperability, and standard compliance. However, benchmarks on high-speed network links are still scarce. This paper presents an extension to the QUIC Interop Runner, a
          framework for testing the interoperability of QUIC implementations. Our contribution enables reproducible QUIC benchmarks on dedicated hardware and high-speed links. We provide results on 10G links, including multiple implementations, evaluate how OS features like buffer sizes and NIC offloading impact QUIC performance, and show which data rates can be achieved with QUIC compared to TCP. Moreover, we analyze different CPUs and CPU architectures influence reproducible and comparable
          performance measurements. Furthermore, our framework can be applied to evaluate the effects of future improvements to the protocol or the OS. Our results show that QUIC performance varies widely between client and server implementations from around 50Mbit/s to over 6000Mbit/s. We show that the OS generally sets the default buffer size too small. Based on our findings, the buffer size should be increased by at least an order of magnitude. Our profiling analysis identifies Packet I/O as
          the most expensive task for QUIC implementations. Furthermore, QUIC benefits less from AES NI hardware acceleration while both features improve the goodput of TCP to around 8000Mbit/s. The lack of support for NIC offloading from QUIC implementations results in missed opportunities for performance improvement. The assessment of CPUs from different vendors and generations revealed significant performance variations. We employed core pinning to examine if the performance of QUIC
          implementations is affected by the allocation to specific CPU cores. The results indicated an increased goodput of up to 20% when running on a specifically chosen core compared to a randomly assigned core. This outcome highlights the impact of CPU core selection on the performance of QUIC implementations but also for reproducible measurements.},
  month = jul,
  homepage = {https://github.com/tumi8/quic-10g-paper}
}
