@journal{sattler2023hrps,
    author = {Sattler, Patrick and Zirngibl, Johannes and Jonker, Mattijs and Gasser, Oliver and Carle, Georg and   Holz, Ralph},
    title = {{Packed to the Brim: Investigating the Impact of Highly Responsive Prefixes on Internet-Wide           Measurement Campaigns}},
    year = {2023},
    file = {sattler2023hrps.pdf},
    url = {https://doi.org/10.1145/3629146},
    doi = {10.1145/3629146},
    abstract = {Internet-wide scans are an important tool to evaluate the deployment of services. To enable large-  scale application layer scans, a fast, stateless port scan (e.g., using ZMap) is often performed ahead of time to   collect responsive targets. It is a common expectation that port scans on the entire IPv4 address space provide a   relatively unbiased view as they cover the complete address space. Previous work, however, has found prefixes where all addresses share particular properties. In IPv6, aliased prefixes and fully responsive prefixes, i.e., prefixes  where all addresses are responsive, are a well-known phenomenon. However, there is no such in-depth analysis for    prefixes with these responsiveness patterns in IPv4.This paper delves into the underlying factors of this           phenomenon in the context of IPv4 and evaluates port scans on a total of 161 ports (142 TCP \& 19 UDP ports) from   three different vantage points. To account for packet loss and other scanning artifacts, we propose the notion of a new category of prefixes, which we call highly responsive prefixes (HRPs). Our findings show that the share of HRPs can make up 70\% of responsive addresses on selected ports. Regarding specific ports, we observe that CDNs          contribute to the largest fraction of HRPs on TCP/80 and TCP/443, while TCP proxies emerge as the primary cause of  HRPs on other ports. Our analysis also reveals that application layer handshakes to targets outside HRPs are,       depending on the chosen service, up to three times more likely to be successful compared to handshakes with targets located in HRPs. To improve future scanning campaigns conducted by the research community, we make our study's data publicly available and provide a tool for detecting HRPs. Furthermore, we propose an approach for a more efficient, ethical, and sustainable application layer target selection. We demonstrate that our approach has the potential to  reduce the number of TLS handshakes by up to 75\% during an Internet-wide scan while successfully obtaining 99 \%   of all unique certificates.},
    journal = {Proc. ACM Netw.},
    month = {nov},
    day = {28},
    homepage = {https://hrp-stats.github.io/},
}

@journal{sosnowski2024efactls,
  author = {Sosnowski, Markus and Zirngibl, Johannes and Sattler, Patrick and Carle, Georg and Grohnfeldt, Claas and Russo, Michele and Sgandurra, Daniele},
  journal = {{IEEE Transactions on Network and Service Management}},
  title = {{EFACTLS: Effective Active TLS Fingerprinting for Large-scale Server Deployment Characterization}},
  abstract = {Active measurements allow the collection of server characteristics on a large scale that can aid in discovering hidden relations and commonalities among server deployments. Finding these relations opens up new possibilities for clustering and classifying server deployments; for example, identifying a previously unknown cybercriminal infrastructure can be valuable cyber-threat intelligence. In this work, we propose a methodology based on  active measurements to acquire Transport Layer Security (TLS) metadata from servers and leverage it for fingerprinting. Our fingerprints capture characteristic behavior of the TLS stack, primarily influenced by the serverâ€™s         implementation, configuration, and hardware support. Using an empirical optimization strategy that maximizes information gained from every handshake to minimize measurement costs, we generated 10 general-purpose Client Hellos. They served as scanning probes to create an extensive database of TLS configurations to classify servers. We propose the Shannon Entropy to measure collected information and compare different approaches. This study fingerprinted 8       million servers from the Tranco top list and two Command and Control (C2) blocklists over 60 weeks with weekly snapshots. The resulting data formed the foundation for two long-term case studies: classification of Content Delivery   Network and C2 servers. Moreover, the detection was fine-grained enough to detect C2 server families. The proposed methodology demonstrated a precision of 99% and enabled a stable identification of new servers over time. This study shows how active measurements can provide valuable security-relevant insights and improve our understanding of the Internet.},
  year={2024},
  month = feb,
  doi={10.1109/TNSM.2024.3364526},
  Homepage = {https://tumi8.github.io/active-tls-fingerprinting/},
  rawdata = {https://doi.org/10.14459/2024mp1733820},
}
